from flask import Flask, request, jsonify, render_template

import os
from werkzeug.utils import secure_filename
import google.generativeai as genai
import cv2
from PIL import Image
import re
import random
from pytesseract import pytesseract
import pyttsx3
import speech_recognition as sr
from openai import OpenAI
import datetime
import inflect
import re
import requests
from pyngrok import ngrok
from serpapi import GoogleSearch
from pyht import Client
from dotenv import load_dotenv
from pyht.client import TTSOptions
from pydub import AudioSegment
from pydub.playback import play
load_dotenv()

client = Client(
    user_id="",
    api_key="",
  
  	# for on-prem users, uncomment and add the advanced grpc_addr option below. Replace grpc_addr with your endpoint. 
  	# advanced=client.Client.AdvancedOptions(grpc_addr="{your-endpoint}.on-prem.play.ht:11045")
)
options = TTSOptions(voice="s3://voice-cloning-zero-shot/60cdb213-83ae-490c-99c9-7e717a9def0b/original/manifest.json")





app = Flask(__name__)

#ngrok_tunnel = ngrok.connect(5000)

# Get the public URL generated by ngrok
#public_url = ngrok_tunnel.public_url
#print("ngrok tunnel running at:", public_url)
serpApi_Key=''

output_text = ""
inital_prompt=' you are a robot with eyes and the image above is what you see infront of you, describe the image you see in one or two sentences '
prompt='fail'
genai.configure(api_key='')  # Replace with your actual API key

model = genai.GenerativeModel('gemini-pro')
chat = model.start_chat(history=[])

UPLOAD_FOLDER = './captured_images/'
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}
MAX_FILESIZE = 500000  # Maximum file size allowed (in bytes)

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def record_audio():
    global prompt
    texts = ["Hello", "hi!", "yes, im listening", "whats up?"]
    random.shuffle(texts)  # Shuffle the list randomly
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        read_aloud(texts[0])
        audio = recognizer.listen(source)
        read_aloud("Recording completed.")
    
    return audio

def convert_audio_to_text(audio):
    global prompt
    # Initialize recognizer
    recognizer = sr.Recognizer()
    
    try:
        # Recognize the audio and convert it to text
        text = recognizer.recognize_google(audio)
        print("Prompt:", text)
        return text
    except sr.UnknownValueError:
        read_aloud("could not understand, please repeat")
        return("fail")
    except sr.RequestError as e:
        print("Could not request results; {0}".format(e))

def read_aloud(text):
    audio_data = client.tts(text,options)  
    file_path = "audio_output.wav"
    with open(file_path, "wb") as f:
        for chunk in audio_data:
            f.write(chunk)    
    audio = AudioSegment.from_wav(file_path)

  # Play the audio
    play(audio)  

def tesseract(image):
    path_to_tesseract = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
    pytesseract.tesseract_cmd = path_to_tesseract
    text = pytesseract.image_to_string(Image.fromarray(image))
    return text
def filter_special_characters(text):
    # Define a regex pattern to match any non-alphanumeric characters
    pattern = r'[^a-zA-Z0-9\s]'
    
    # Use re.sub() to replace all non-alphanumeric characters with an empty string
    filtered_text = re.sub(pattern, '', text)
    
    return filtered_text
# Define the route to run the Python script

def format_results_paragraph(organic_results, sports, top_stories, answer_box):
    organic_text = "organic results: " + organic_results
    sports_text = "sports results: " + sports
    
    # Convert top_stories to a list of titles
    top_stories_titles = [story["title"] for story in top_stories]
    top_stories_text = "top stories: " + ', '.join(top_stories_titles) + '\n' if top_stories else ""
    
    # Handle answer_box being None
    answer_box_text = "answer box: " + answer_box["snippet"] + '\n' if answer_box and answer_box.get("snippet") else ""
    
    return '\n'+organic_text +'\n'+ sports_text +'\n'+ top_stories_text +'\n'+ answer_box_text


@app.route('/get_output_text', methods=['GET'])
def get_output_text():
    global output_text
    current_time = datetime.datetime.now()
    

    return jsonify({'output_text': output_text})




@app.route('/conversation', methods=['POST'])
def conversation():
    global chat, client, options, serpApi_Key
    prompt = 'fail'
    inital_conversation_prompt ='''
        'you are a conversational AI for blind named VISION developed by Abhishek, Akshay, Ananya and Akhil.' 
        'Limit your answers to one or two sentences. answer in paragraph only when asked to.'
        'Give outputs in a way a human would talk'.
        'only if the person says a greeting word for the first time you are supposed to introduce yourself as vision or just say the answer directly.'
        'if a question is asked answer to the question precisely instead of giving all details.'
        'Do not ever tell "I don't have access to real-time data".
          '''
    
    
    safe = [
            {
                "category": "HARM_CATEGORY_HARASSMENT",
                "threshold": "BLOCK_NONE",
            },
            {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "threshold": "BLOCK_NONE",
            },
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_NONE",
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_NONE",
            },
        ]
    if request.method == 'POST':
        current_time = datetime.datetime.now()
        p = inflect.engine()

        if current_time.hour == 0:
            hour_text = "twelve"
        elif current_time.hour <= 12:
            hour_text = p.number_to_words(current_time.hour)
        else:
            hour_text = p.number_to_words(current_time.hour - 12)
            
        if current_time.minute == 0:
            minute_text = "o'clock"
        else:
            minute_text = p.number_to_words(current_time.minute)

        if current_time.hour < 12:
            period_text = "a.m."
        else:
            period_text = "p.m."

        time_text = f"It's {hour_text} {minute_text} {period_text}."
        date_text = f" {current_time.strftime('%A, %B %d, %Y')}."

        if 'value' in request.form:
            received_value = request.form['value']
            print("Received value:", received_value)
            
            if received_value == '1':
                while prompt == 'fail':
                    audio = record_audio()
                    prompt = convert_audio_to_text(audio)
                
                try: 
                    search_query = prompt
                    params = {
                            "engine": "google",
                            "q": search_query,
                            "api_key": serpApi_Key
                            }
                    search = GoogleSearch(params)
                    search_results = search.get_dict()
                    #print(search_results['organic_results'])
                    # Extract organic results
                    organic_results = ""
                    organic_result=search_results['organic_results']
                    for result in organic_result:
                        organic_results += f"{result['position']}. {result['snippet']}\n"
                    
                   # print("organic results=",organic_results)
                    # Extract sports results
                    #sports_results = {}
                    sports_data = search_results.get("sports_results", {})
                    print("test sports data= ", sports_data)
                    sports=''
                    if sports_data:
                        if sports_data['game_spotlight']['teams']:
                            sports+= f"Live score"
                            for team in sports_data['game_spotlight']['teams']:
                                sports += f" {team['name']} {team['score']}"
                            sports+= f"\n"    
                        for game in sports_data['games']:
                            for idx, team in enumerate(game['teams'], start=1):
                                sports += f"{idx}. {team['name']} {team['score']}\n"

                    # Extract top stories
                    top_stories = []
                    related_questions = search_results.get("top_stories", [])
                    for story in related_questions:
                        top_stories.append({
                            "title": story.get("title", None),
                            "date": story.get("date", None)
                        })

                    # Extract answer box
                    answer_box = {
                        "snippet": search_results.get("answer_box", {}).get("snippet", None)
                    }
                                
                    
                    concatenated_titles=format_results_paragraph(organic_results, sports, top_stories,answer_box)
                    #print(concatenated_titles)
                    #response = requests.get('https://serpapi.com/search?engine=google_news&q=', params=params)
                    #news_data = response.json()

                    #search_res = ""
                    concatenated_titles=concatenated_titles.replace('/',' for ')
                    
                    print("search result is:", concatenated_titles)
                    response = chat.send_message(inital_conversation_prompt + prompt + ". The news search result for the above prompt is as given below. Please answer accordingly using this as reference if asked for real-time data:\n\n" + concatenated_titles + "\n\nIf asked about the current time, tell it's " + time_text + "\n\nIf asked about the current date, tell it's " + date_text, stream=True,safety_settings=safe)
                except Exception as e:
                    print("Error:", e)
                    chat.rewind()
                    response = chat.send_message(inital_conversation_prompt + prompt)

                text = ''
                for chunk in response:
                    text = text + chunk.text
                read_aloud(text)

                print(text)
                prompt = 'fail'
                
                return "Received value: " + received_value
            else:
                return "No value received"

    return "test"
    


@app.route('/post_images', methods=['POST'])
def upload_file():
    if 'imageFile' not in request.files:
        return jsonify({'error': 'No file part'})
    
    file = request.files['imageFile']
    
    if file.filename == '':
        return jsonify({'error': 'No selected file'})
    
    if file and allowed_file(file.filename):
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        
        # Check file size
        if os.stat(filepath).st_size > MAX_FILESIZE:
            return jsonify({'error': 'File size exceeds maximum allowed size'})
        
        file.save(filepath)
        img = Image.open(filepath)
        
        # Rotate the image by 45 degrees
        rotated_img = img.rotate(180)
        
        # Save the rotated image
        rotated_img.save(filepath)
        other_data = file.filename
        print(other_data)
        if(other_data=='image(1).jpg'):
            global  inital_prompt
            model = genai.GenerativeModel('gemini-pro-vision')
            image = Image.open('captured_images/image1.jpg')
                
            response = model.generate_content([inital_prompt, image])
            text = ''

            for chunk in response:
                text = text + chunk.text
            read_aloud(text)
            
            out=text
            return out
        elif(other_data=='image(2).jpg'):
            model = genai.GenerativeModel('gemini-pro-vision')
            image = Image.open('captured_images/image2.jpg')
                
            response = model.generate_content(['detect only the text in the image and nothing else', image])
            text = ''

            for chunk in response:
                text = text + chunk.text
            read_aloud(text)
            
            out=text
            return out
        return jsonify({'message': 'File successfully uploaded', 'filename': filename})
    else:
        return jsonify({'error': 'File type not allowed'})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
